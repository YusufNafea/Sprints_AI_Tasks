# StreamPulse â€“ Module 1: ML Workflow Setup & Baseline Churn Prediction

## ğŸ“Œ Project Overview

This project represents **Module 1** of the *StreamPulse* machine learning pipeline. The goal is to establish a complete, reproducible **end-to-end ML workflow** using a baseline supervised learning model to predict **customer churn**.

The module covers:

* Data loading and inspection
* Feature preprocessing (scaling + encoding)
* Model training and evaluation
* Cross-validation and hyperparameter tuning
* Model persistence for future use

This baseline serves as a reference point for more advanced modeling in later modules.

---

## ğŸ› ï¸ Technologies Used

* **Python 3**
* **Pandas / NumPy** â€“ data handling
* **Scikit-learn** â€“ preprocessing, modeling, evaluation
* **Joblib** â€“ model persistence

---

## ğŸ“‚ Project Structure

```text
stream_pulse_project/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ Stream_pulse_customer_data.csv
â”œâ”€â”€ models/
â”‚   â””â”€â”€ baseline_model.pkl
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ m1_baseline_model.py
â”‚   â””â”€â”€ preprocessing_pipeline.pkl
â””â”€â”€ README.md
```

---

## ğŸ“Š Dataset Description

The dataset contains customer-level information related to usage behavior and subscription details.

### Key Columns:

* `customer_id` â€“ unique customer identifier
* `age` â€“ customer age
* `country` â€“ customer country
* `subscription_type` â€“ Free / Basic / Premium
* `monthly_spend` â€“ average monthly spending
* `sessions_per_month` â€“ usage frequency
* `avg_watch_time_min` â€“ average watch time
* `churned` â€“ **target variable** (1 = churned, 0 = not churned)

---

## âš™ï¸ ML Workflow Summary

### 1. Data Preprocessing

* Categorical features encoded using **OneHotEncoder**
* Numerical features standardized using **StandardScaler**
* Preprocessing handled via **ColumnTransformer**

### 2. Train-Test Split

* 70% training / 30% testing
* **Stratified split** to preserve churn distribution

### 3. Baseline Model

* **Logistic Regression** classifier
* Implemented using a unified Scikit-learn **Pipeline**

### 4. Model Evaluation

Metrics computed on the test set:

* Accuracy
* Precision
* Recall

### 5. Cross-Validation

* 5-fold cross-validation on training data
* Used to assess model stability

### 6. Hyperparameter Tuning

* GridSearchCV with 3 parameter combinations
* Optimized regularization strength (`C`)

---

## ğŸ“ˆ Results Interpretation

* The baseline model achieves ~81% accuracy
* Precision and Recall for churn are low due to **class imbalance**
* This behavior is expected for a baseline churn model

These results motivate more advanced techniques in future modules, such as:

* Class weighting
* Resampling (SMOTE)
* Tree-based models

---

## ğŸ’¾ Saved Artifacts

After execution, the following files are generated:

* `models/baseline_model.pkl` â€“ trained Logistic Regression model
* `src/preprocessing_pipeline.pkl` â€“ preprocessing pipeline

These artifacts can be reused directly for inference or further training.

---

## â–¶ï¸ How to Run

From the project root directory:

```bash
python src/m1_baseline_model.py
```

---

## âœ… Module Status

* âœ” End-to-end ML workflow implemented
* âœ” Baseline model trained and evaluated
* âœ” Ready for **Module 2: Feature Engineering & Advanced Models**

---

## ğŸ“Œ Notes

This module focuses on **correctness and structure**, not optimal churn detection performance. Improving recall and precision is addressed in later stages of the project.

---

**Author:** StreamPulse Project
**Module:** ML Workflow Setup & Baseline Churn Prediction
